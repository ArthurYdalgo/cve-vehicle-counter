import numpy as np
import cv2
import sys

class LaneCounter(object):
    """
    Responsible for counting passing entities in a determined area

    Parameters
    ----------
    footage_source : str or int
        The file name or index of video source. In case the source is a video, such file must be in the 'test footage' directory
    look_for : list
        List of classes to be looked for
    confidence_threshold : float (from 0 to 1)
        Detection confidence threshold
    nms_threshold : float (from 0 to 1)
        NMS confidence threshold
    search_area : dictionary 
        Dictionary that defines search area attributes.
        The dictionary must contain a 'position' key and a 'dimension' key, and
            each key contains a tuple of the desired x/y and width/height values
        e.g.: {'position':(715,475),'dimension':(150,35)}
    """

    def __init__(self, footage_source='road footage.mp4', look_for=['car', 'motorbike'], confidence_threshold=0.5, nms_threshold=0.3, search_area={'position': (715, 475), 'dimension': (150, 35)},crop=True):

        # LaneCounter changable properties
        self.footage_source = footage_source
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.look_for = look_for

        # Model cfg and weights files
        self.model_cfg_file_name = 'yolov3.cfg'
        self.model_weights_file_name = 'yolov3.weights'

        # Classes file
        self.coco_classes_file_name = 'coco.names'
        self.coco_classes = self.getCocoClasses(self.coco_classes_file_name)

        # Input layer shape
        self.width = 416
        self.height = 416

        # Counting variables
        self.entities_counter = {}
        self.entities_in_search_area = {}

        # Sets counter and ocupation counter of every entity to 0
        for entity in look_for:
            self.entities_counter[entity] = 0
            self.entities_in_search_area[entity] = 0

        self.crop = crop
        # Search area properties
        try:
            self.search_area_width = int(search_area['dimension'][0])
            self.search_area_height = int(search_area['dimension'][1])
            self.search_area_x = int(search_area['position'][0])
            self.search_area_y = int(search_area['position'][1])
        except:
            print('Invalid search area')
            sys.exit()

        # Footage frame properties
        self.frame_height = None
        self.frame_width = None
        self.frame_channel = None

    def drawEntities(self, frame, nms_indexes, detection_frames, detection_confidence_levels, detection_confidence_levels_indexes, draw_text=True):
        """
        Draws entities. Text can be removed by setting the 'draw_text' parameter to False
        """
        for _nms_index in nms_indexes:

            # Retrieves nms_index, detection frame, x, y, width and height to be later used when drawing detection frame
            nms_index = _nms_index[0]

            detection_frame = detection_frames[nms_index]

            x, y = detection_frame[0], detection_frame[1]

            width, height = detection_frame[2], detection_frame[3]

            # Draws the entity area in the footage
            # For more info regarding cv2.rectangle(), go to: https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga07d2f74cadcf8e305e810ce8eed13bc9
            cv2.rectangle(frame, (x, y), (x + width,
                                          y + height), (0, 200, 0), 2)

            # Draws the entity's description (index, class and detection confidence) in the footage
            # For more info regarding cv2.putText(), go to: https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576
            if(draw_text):
                cv2.putText(frame, "[{}]{} - {} %".format(
                    nms_index,
                    self.coco_classes[detection_confidence_levels_indexes[nms_index]].upper(
                    ),
                    int(100*detection_confidence_levels[nms_index])),
                    (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 0, 200), 2)
        
    def drawCounters(self,frame):
        """
        Draws entities' counters. In case too many class are added to the look_for parameter, they might not
            fit inside the footage
        """
        y = 20
        for entity in self.look_for:            
            cv2.putText(frame, "{} - {}".format(entity,self.entities_counter[entity]),
                (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 0, 200), 2)
            y+=20

    def drawSearchArea(self, frame):
        """
        Draws search area
        """

        # Draws the search area in the footage
        # For more info regarding cv2.rectangle(), go to: https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga07d2f74cadcf8e305e810ce8eed13bc9
        if(self.crop):
            cv2.rectangle(frame,
                        (100,100),
                        (self.search_area_width + 100,self.search_area_height + 100),
                        (0, 0, 200), 2)
        else:
            cv2.rectangle(frame,
                        (int(self.search_area_x - self.search_area_width / 2),
                        int(self.search_area_y - self.search_area_height / 2))
                        ,
                        (int(self.search_area_x + self.search_area_width / 2),
                        int(self.search_area_y + self.search_area_height / 2)),
                        (0, 0, 200), 2)


    def setup(self):
        """
        Responsible for instantiating footage and network
        """
        footage = self.getFootage()

        # Instantiates network, or exits the program if an error is found
        try:
            model_cfg = self.model_cfg_file_name
            model_weights = self.model_weights_file_name

            network = self.getNetwork(model_cfg, model_weights)
        except:
            print('Model cfg/weights invalid/not found')
            sys.exit()

        # Get layers names
        layer_names = network.getLayerNames()

        # Gets index of output layers
        output_layers = network.getUnconnectedOutLayers()

        output_layer_names = []

        # Gets output layers' names
        for layer in output_layers:
            output_layer_names.append(layer_names[layer[0]-1])

        return footage, network, output_layer_names

    def isInsideSerchArea(self, x, y):
        """
        Checks wether or not given coordinates are inside search area
        """
        if(self.crop):
            if( x >= 100 and 
                x <= self.search_area_width + 100 and
                y >= 100 and 
                y <= self.search_area_height + 100 
                ):
                return True
        else:
            if( x >= int(self.search_area_x - self.search_area_width / 2) and 
                x <= int(self.search_area_x + self.search_area_width / 2) and
                y >= int(self.search_area_y - self.search_area_height / 2) and 
                y <= int(self.search_area_y + self.search_area_height / 2) 
                ):
                return True
        
        return False
        

    def entitiesCounter(self, nms_indexes, detection_frames, detection_confidence_levels, detection_confidence_levels_indexes):
        # Creates a local entities ocupation counter for each class and sets it to 0
        entities_counter = {}

        for entity in self.look_for:
            entities_counter[entity] = 0

        # Iterates through nms indexes
        for _nms_index in nms_indexes:

            nms_index = _nms_index[0]

            entity_class = self.coco_classes[detection_confidence_levels_indexes[nms_index]]

            detection_frame = detection_frames[nms_index]

            x, y = detection_frame[0], detection_frame[1]            

            # For each detection, if it's inside the search area, the ocupation of that class is incremented
            if(self.isInsideSerchArea(x,y)):
                entities_counter[entity_class]+=1
            
        
        # Every time the ocupation of a given class varies positively, a new entity of a class is considered
        #   to have entered the area and the counter of that class is increment by the ocupation positive variation
        for entity in self.look_for:
            if(entities_counter[entity]>self.entities_in_search_area[entity]):
                self.entities_counter[entity] += entities_counter[entity] - self.entities_in_search_area[entity]
            
            # and the ocupation is updated
            self.entities_in_search_area[entity] = entities_counter[entity]            

    def count(self, display=True):
        """
        Counts how many entities pass through search area. 
        To exit counting, press q

        Parameters
        ----------
        display : bool
            In case the footage isn't needed, this parameter can be set to False            

        """
        footage, network, output_layer_names = self.setup()

        while(footage.isOpened()):
            ret, frame = footage.read()

            # Converts footage to blob and crops it (in case crop flag is set as True)
            #
            # For more info regarding cv2.dnn.blobFromImage(), go to: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7

            if(self.crop):
                try:
                    x_1 = int(self.search_area_x - self.search_area_width/2) - 100
                    if(x_1 < 0):
                        x_1 = 0

                    x_2 = int(self.search_area_x + self.search_area_width/2) + 100
                    if(x_2 >= frame.shape[1]):
                        x_2 = frame.shape[1] - 1

                    y_1 = int(self.search_area_y - self.search_area_height/2) - 100
                    if(y_1 < 0):
                        y_1 = 0

                    y_2 = int(self.search_area_y + self.search_area_height/2) + 100
                    if(y_2 >= frame.shape[0]):
                        y_2 = frame.shape[0] - 1

                    frame = frame[y_1:y_2,x_1:x_2]
                except:
                    print('Invalid search area')

            footage_as_blob = cv2.dnn.blobFromImage(
                frame, 1/255, (self.width, self.height), [0, 0, 0], 1, crop=False)

            # Sets created network input
            network.setInput(footage_as_blob)

            # Gets output
            output_layers = network.forward(output_layer_names)

            # Output is filtered
            nms_index, detection_frames, detection_confidence_levels, detection_confidence_levels_indexes = self.filter(
                output_layers,frame)

            # Counts entities passing by search area
            self.entitiesCounter(nms_index, detection_frames,
                                 detection_confidence_levels, detection_confidence_levels_indexes)

            # Displays counting
            self.drawCounters(frame)
            
            # Displays footage and detection (can be disable)
            if(display):
                self.drawSearchArea(frame)

                self.drawEntities(frame, nms_index, detection_frames,
                                  detection_confidence_levels, detection_confidence_levels_indexes,draw_text=False)
                cv2.imshow('CVE Footage', frame)

            # Press q to exit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break            

        footage.release()
        cv2.destroyAllWindows()

        # Returns counting
        return self.entities_counter

    def filter(self, output_layers,frame):
        """
        Filters overlapping detections
        """
        self.frame_height, self.frame_width, self.frame_channel = frame.shape

        detection_frames = []
        detection_confidence_levels = []
        detection_confidence_levels_indexes = []

        # Iterates through output layers ...
        for output_layer in output_layers:
            # ... and through each detection of such layers
            for detection in output_layer:

                # The first 5 indexes of each detection are:
                # - x position of detection area
                # - y position of detection area
                # - width of detection area
                # - heigh of of detection area
                # - confidence of detection
                # the remainig indexes are the probabilities of each class (person, bicycle, car...) truly being the detected entity

                # np.argmax returns the index of the most problable class
                detection_scores = detection[5:]
                max_confidence_level_index = np.argmax(detection_scores)

                # Identification class
                entity_class = self.coco_classes[max_confidence_level_index]

                # The mentioned probability value is compared to a threshold, and the entity class is compared to a list of acceptable classes
                #   and if all requirement are achieved, the detection is stored
                max_confidence_level = detection_scores[max_confidence_level_index]
                if(max_confidence_level > self.confidence_threshold and entity_class in self.look_for):
                    width = int(detection[2] * self.frame_width)
                    height = int(detection[3] * self.frame_height)
                    x = int(detection[0] * self.frame_width - width / 2)
                    y = int(detection[1] * self.frame_height - height / 2)

                    detection_frames.append([x, y, width, height])
                    detection_confidence_levels_indexes.append(
                        max_confidence_level_index)

                    detection_confidence_levels.append(
                        float(max_confidence_level))

        # The stored detections are then suppressed given boxes and corresponding scores.
        #
        # For more info regarding cv2.dnn.NMSBoxes(), go to: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga9d118d70a1659af729d01b10233213ee
        nms_index = cv2.dnn.NMSBoxes(
            detection_frames, detection_confidence_levels, self.confidence_threshold, self.nms_threshold)

        return nms_index, detection_frames, detection_confidence_levels, detection_confidence_levels_indexes

    def getCocoClasses(self, coco_classes_file_name):
        """
        Gets coco classes
        """        
        with open(coco_classes_file_name, 'rt') as coco_file:
            return coco_file.read().rstrip('\n').split('\n')

    def getNetwork(self, model_cfg_file_name, model_weights_file_name):
        """
        Instantiates network
        """

        # Reads a network model stored in Darknet model files.
        #
        # For more info regarding cv2.readNetFromDarknet(), go to: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#gafde362956af949cce087f3f25c6aff0d
        network = cv2.dnn.readNetFromDarknet(
            model_cfg_file_name, model_weights_file_name)

        # Sets computational backend and target
        network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
        network.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

        return network

    def getFootage(self):
        """
        Instantiates OpenCV footage based on source
        """

        # OpenCV's "VideoCapture()" method's parameter is either an index (which is related to a connected source) or a filename
        #
        # For more info regarding cv2.VideoCapture(), go to: https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html#a57c0e81e83e60f36c83027dc2a188e80
        footage = cv2.VideoCapture(self.footage_source)

        # Checks wether or not the given source is a valid one
        if footage is None or not footage.isOpened():
            print('Invalid source')
            sys.exit()

        return footage
